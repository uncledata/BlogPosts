{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as f \n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"Spark Benchmarking\") \\\n",
    "        .master('local[*]') \\\n",
    "        .config('spark.driver.memory', '16g')\\\n",
    "        .config(\"spark.driver.maxResultSize\", \"6g\")\\\n",
    "        .getOrCreate()\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "schema = StructType([StructField('Project ID', StringType(), True),\n",
    "                         StructField('Resource Item Name', StringType(),True),\n",
    "                         StructField('Resource Quantity', DecimalType(), True),\n",
    "                         StructField('Resource Unit Price', DecimalType(), True),\n",
    "                         StructField('Resource Vendor Name', StringType(), True),])\n",
    "\n",
    "def function_to_apply_row(x, y):\n",
    "    return x*y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "35.4 s ± 1.1 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
    }
   ],
   "source": [
    "%timeit resources = spark.read.load('./data/Resources.csv', format=\"csv\", header='true', schema=schema).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+--------------------+--------------------+-----------------+-------------------+--------------------+\n|          Project ID|  Resource Item Name|Resource Quantity|Resource Unit Price|Resource Vendor Name|\n+--------------------+--------------------+-----------------+-------------------+--------------------+\n|000009891526c0ade...|chair move and st...|                1|                350|                null|\n|00000ce845c00cbf0...|sony mdr zx100 bl...|               40|                 13|               CDW-G|\n|00002d44003ed46b0...|gaiam kids stay-n...|                4|                 19|     Amazon Business|\n|00002d44003ed46b0...|cf520x - giant co...|                1|                269|Lakeshore Learnin...|\n|00002d44003ed46b0...|serta lounger, mi...|                1|                132|     Amazon Business|\n|00002d44003ed46b0...|big joe roma bean...|                2|                 34|     Amazon Business|\n|00002eb25d60a09c3...|m48 carton of 6 m...|                3|                172|Woodwind and Bras...|\n|0000300773fe015f8...|       show and tell|                1|                  6|     Amazon Business|\n|0000300773fe015f8...|it's my turn (lit...|                1|                 24|     Amazon Business|\n|0000300773fe015f8...|a funny first day...|                1|                  6|     Amazon Business|\n|0000300773fe015f8...|what am i? where ...|                1|                  3|     Amazon Business|\n|0000300773fe015f8...|a day with may le...|                1|                  5|     Amazon Business|\n|0000300773fe015f8...|in the yard (comp...|                1|                  8|     Amazon Business|\n|0000300773fe015f8...|snow joe (rookie ...|                1|                  5|     Amazon Business|\n|0000300773fe015f8...|todd's box (green...|                1|                  4|     Amazon Business|\n|0000300773fe015f8...|see me dig (i lik...|                1|                  4|     Amazon Business|\n|0000300773fe015f8...|just clowning aro...|                1|                  4|     Amazon Business|\n|0000300773fe015f8...|late nate in a ra...|                1|                  7|     Amazon Business|\n|0000300773fe015f8...|my camp-out (real...|                1|                  5|     Amazon Business|\n|0000300773fe015f8...|a new friend (pen...|                1|                  3|     Amazon Business|\n+--------------------+--------------------+-----------------+-------------------+--------------------+\nonly showing top 20 rows\n\n"
    }
   ],
   "source": [
    "resources = spark.read.load('./data/Resources.csv', format=\"csv\", header='true', schema=schema)\n",
    "resources.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r7 \n",
    "resources.toPandas().to_csv(\"./output/output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r7 \n",
    "resources.coalesce(1).write.format('csv').mode(\"overwrite\").save(f\"./output/output_folder\")\n",
    "for filename in glob.glob('./output/output_folder/*.csv'):\n",
    "    shutil.move(filename, './output/output.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r7 \n",
    "resources.withColumn(\"cost\",function_to_apply_row(f.col(\"Resource Quantity\"),f.col(\"Resource Unit Price\")))\n",
    "resources.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r7 \n",
    "resources = resources.withColumn(\"cost\",f.col(\"Resource Quantity\")*f.col(\"Resource Unit Price\"))\n",
    "resources.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n1 -r7 resources.groupby(\"Resource Vendor Name\").agg({\"Resource Quantity\" : 'mean'})\n",
    "\n",
    "%timeit -n1 -r7 resources.na.fill('0').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "del resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit resources = spark.read.load('./data/resources_v2.csv', format=\"csv\", header='true', schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources = spark.read.load('./data/resources_v2.csv', format=\"csv\", header='true', schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r7 \n",
    "resources.toPandas().to_csv(\"./output/output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r7 \n",
    "resources.coalesce(1).write.format('csv').mode(\"overwrite\").save(f\"./output/output_folder\")\n",
    "for filename in glob.glob('./output/output_folder/*.csv'):\n",
    "    shutil.move(filename, './output/output.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r7 \n",
    "resources = resources.withColumn(\"cost\",function_to_apply_row(f.col(\"Resource Quantity\"),f.col(\"Resource Unit Price\")))\n",
    "resources.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r7 \n",
    "resources = resources.withColumn(\"cost\",f.col(\"Resource Quantity\")*f.col(\"Resource Unit Price\"))\n",
    "resources.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n1 -r7 resources.groupby(\"Resource Vendor Name\").agg({\"Resource Quantity\" : 'mean'}).collect()\n",
    "\n",
    "%timeit -n1 -r7 resources.na.fill('0').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "del resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}